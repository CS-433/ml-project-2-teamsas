{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"idiap\"\n",
    "dataset = \"idiap_chunked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"my_personality\":\n",
    "    target_vars_names = [\n",
    "        \"sEXT\",\n",
    "        \"sNEU\",\n",
    "        \"sAGR\",\n",
    "        \"sCON\",\n",
    "        \"sOPN\",\n",
    "    ]\n",
    "    train = pd.read_csv(\n",
    "        \"data/my_personality/my_personality.csv\",\n",
    "        encoding=\"ISO-8859-1\",\n",
    "    )\n",
    "    train.rename(columns={\"STATUS\": \"text\"}, inplace=True)\n",
    "elif dataset == \"idiap\":\n",
    "    target_vars_names = [\n",
    "        \"hones16\",\n",
    "        \"emoti16\",\n",
    "        \"extra16\",\n",
    "        \"agree16\",\n",
    "        \"consc16\",\n",
    "        \"openn16\",\n",
    "        \"icar_hat0\",\n",
    "        \"icar_hat1\",\n",
    "        \"icar_hat2\",\n",
    "    ]\n",
    "    train = pd.read_excel(\"data/idiap/dataset.xlsx\")\n",
    "    train.rename(columns={\"final_text\": \"text\"}, inplace=True)\n",
    "else:\n",
    "    target_vars_names = [\n",
    "        \"hones16\",\n",
    "        \"emoti16\",\n",
    "        \"extra16\",\n",
    "        \"agree16\",\n",
    "        \"consc16\",\n",
    "        \"openn16\",\n",
    "        \"icar_hat0\",\n",
    "        \"icar_hat1\",\n",
    "        \"icar_hat2\",\n",
    "    ]\n",
    "    train = pd.read_csv(\"data/idiap_chunked/chunked_dataset.csv\")\n",
    "    train.rename(columns={\"chunk_text\": \"text\"}, inplace=True)\n",
    "\n",
    "target_vars = train[target_vars_names]\n",
    "target_vars = (target_vars - target_vars.min()) / (target_vars.max() - target_vars.min())\n",
    "target_vars = target_vars.reset_index(drop=True).to_numpy()\n",
    "texts = train[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bhadresh-savani/bert-base-go-emotion\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "emotion_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "def extract_features(texts):\n",
    "    features = []\n",
    "    for text in tqdm(texts):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = emotion_model(**inputs)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1)\n",
    "        features.append(probabilities[0].numpy())\n",
    "    return np.array(features)\n",
    "\n",
    "features = extract_features(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target_vars, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "\n",
    "class EmotionRegressor(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_units, num_layers, dropout_rate):\n",
    "        super(EmotionRegressor, self).__init__()\n",
    "        layers = []\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(\n",
    "                nn.Linear(\n",
    "                    input_size if len(layers) == 0 else hidden_units, hidden_units\n",
    "                )\n",
    "            )\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "        layers.append(nn.Linear(hidden_units, output_size))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    hidden_units = trial.suggest_int(\"hidden_units\", 32, 256, step=32)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 0.5)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "\n",
    "    model = EmotionRegressor(\n",
    "        input_size=X_train.shape[1],\n",
    "        output_size=y_train.shape[1],\n",
    "        hidden_units=hidden_units,\n",
    "        num_layers=num_layers,\n",
    "        dropout_rate=dropout_rate,\n",
    "    )\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    epochs = 50\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test_tensor).numpy()\n",
    "\n",
    "    rmse_per_output = np.sqrt(\n",
    "        mean_squared_error(y_test, predictions, multioutput=\"raw_values\")\n",
    "    )\n",
    "    mean_rmse = np.mean(rmse_per_output)\n",
    "\n",
    "    mae_per_output = mean_absolute_error(y_test, predictions, multioutput=\"raw_values\")\n",
    "    mean_mae = np.mean(mae_per_output)\n",
    "\n",
    "    return mean_mae\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=40)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "best_params = study.best_params\n",
    "final_model = EmotionRegressor(\n",
    "    input_size=X_train.shape[1],\n",
    "    output_size=y_train.shape[1],\n",
    "    hidden_units=best_params[\"hidden_units\"],\n",
    "    num_layers=best_params[\"num_layers\"],\n",
    "    dropout_rate=best_params[\"dropout_rate\"],\n",
    ")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=best_params[\"learning_rate\"])\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    final_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = final_model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = final_model(X_test_tensor).numpy()\n",
    "\n",
    "mae_per_output = mean_absolute_error(y_test, predictions, multioutput=\"raw_values\")\n",
    "rmse_per_output = np.sqrt(\n",
    "    mean_squared_error(y_test, predictions, multioutput=\"raw_values\")\n",
    ")\n",
    "mean_mae = np.mean(mae_per_output)\n",
    "mean_rmse = np.mean(rmse_per_output)\n",
    "\n",
    "print(\"MAE per output:\", mae_per_output)\n",
    "print(\"RMSE per output:\", rmse_per_output)\n",
    "print(\"Mean MAE:\", mean_mae)\n",
    "print(\"Mean RMSE:\", mean_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
