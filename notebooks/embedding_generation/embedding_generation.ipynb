{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding the Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we precompute the embeddings of the texts using different models. This will help us to quickly load the embeddings in the future and to avoid recomputing them in each iteration and in each model training. the embeddings are saved along with the data.\n",
    "\n",
    "Note that these embeddings are only usable when we are considering the model freezed. In the fine tuning procedures, precomputed embeddings are not used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution: the code has been executed on a local machine for the main dataset due to Swiss regulations and on Google Colab for public datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1983, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>collective</th>\n",
       "      <th>contrast</th>\n",
       "      <th>goal</th>\n",
       "      <th>goals2</th>\n",
       "      <th>list</th>\n",
       "      <th>metaphor</th>\n",
       "      <th>moral</th>\n",
       "      <th>question</th>\n",
       "      <th>story</th>\n",
       "      <th>...</th>\n",
       "      <th>final_text</th>\n",
       "      <th>overall_sentiment_all</th>\n",
       "      <th>positive_sentiment_all</th>\n",
       "      <th>negative_sentiment_all</th>\n",
       "      <th>neutra_sentiment_all</th>\n",
       "      <th>mixed_sentiment_all</th>\n",
       "      <th>targets</th>\n",
       "      <th>text_length_all</th>\n",
       "      <th>prolific_score</th>\n",
       "      <th>prolific_indicator_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e1cf0eb65b6d3071f489de9</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.32</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>Hello everyone. Thank you. Taking the time to ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.9569</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>771.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55d06fd334e9060012e5781c</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>Hi, I am Kathy. I'd love to be considered for ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>MED</td>\n",
       "      <td>424.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>615586b009f801c3f2d4af8d</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.26</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>uh yeah I I think I would be the best candidat...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.8051</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.1747</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>MED</td>\n",
       "      <td>449.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5847e60f73170700013697c6</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.12</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.09</td>\n",
       "      <td>...</td>\n",
       "      <td>Hello. Um I've of course a fair amount of expe...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.5761</td>\n",
       "      <td>0.1185</td>\n",
       "      <td>0.2484</td>\n",
       "      <td>0.0570</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>611.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6086a11397234e7f83e4e793</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.76</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.22</td>\n",
       "      <td>7.92</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>Okay, so I would like to thank you for giving ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.8515</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.1456</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>611.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             participant_id  collective  contrast  goal  goals2  list  \\\n",
       "0  5e1cf0eb65b6d3071f489de9        0.35      1.07  0.43    0.32  6.96   \n",
       "1  55d06fd334e9060012e5781c        0.30      0.67  0.30    0.20  2.83   \n",
       "2  615586b009f801c3f2d4af8d        0.18      0.74  0.16    0.26  3.40   \n",
       "3  5847e60f73170700013697c6        0.14      2.14  0.27    0.12  3.05   \n",
       "4  6086a11397234e7f83e4e793        0.90      4.76  0.86    0.22  7.92   \n",
       "\n",
       "   metaphor  moral  question  story  ...  \\\n",
       "0      0.94   2.36      0.01   0.46  ...   \n",
       "1      0.71   0.22      0.01   0.60  ...   \n",
       "2      1.10   1.09      0.01   0.37  ...   \n",
       "3      0.49   0.46      0.00   1.09  ...   \n",
       "4      0.56   2.95      0.01   0.19  ...   \n",
       "\n",
       "                                          final_text  overall_sentiment_all  \\\n",
       "0  Hello everyone. Thank you. Taking the time to ...               POSITIVE   \n",
       "1  Hi, I am Kathy. I'd love to be considered for ...                NEUTRAL   \n",
       "2  uh yeah I I think I would be the best candidat...               POSITIVE   \n",
       "3  Hello. Um I've of course a fair amount of expe...               POSITIVE   \n",
       "4  Okay, so I would like to thank you for giving ...               POSITIVE   \n",
       "\n",
       "   positive_sentiment_all  negative_sentiment_all neutra_sentiment_all  \\\n",
       "0                  0.9569                  0.0007               0.0417   \n",
       "1                  0.1587                  0.0055               0.8350   \n",
       "2                  0.8051                  0.0164               0.1747   \n",
       "3                  0.5761                  0.1185               0.2484   \n",
       "4                  0.8515                  0.0016               0.1456   \n",
       "\n",
       "  mixed_sentiment_all targets  text_length_all  prolific_score  \\\n",
       "0              0.0007    HIGH            771.0           100.0   \n",
       "1              0.0009     MED            424.0            99.0   \n",
       "2              0.0039     MED            449.0           100.0   \n",
       "3              0.0570    HIGH            611.0           100.0   \n",
       "4              0.0013    HIGH            611.0           100.0   \n",
       "\n",
       "   prolific_indicator_all  \n",
       "0                       2  \n",
       "1                       2  \n",
       "2                       2  \n",
       "3                       2  \n",
       "4                       2  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_excel(\"../../data/dataset.xlsx\")\n",
    "data_df = data_df.dropna()\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "data_df = data_df.drop(columns=[\"Unnamed: 0\"])\n",
    "print(data_df.shape)\n",
    "data_df_texts = data_df[\"final_text\"]\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4988, 51)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>collective</th>\n",
       "      <th>contrast</th>\n",
       "      <th>goal</th>\n",
       "      <th>goals2</th>\n",
       "      <th>list</th>\n",
       "      <th>metaphor</th>\n",
       "      <th>moral</th>\n",
       "      <th>question</th>\n",
       "      <th>story</th>\n",
       "      <th>...</th>\n",
       "      <th>positive_sentiment_all</th>\n",
       "      <th>negative_sentiment_all</th>\n",
       "      <th>neutra_sentiment_all</th>\n",
       "      <th>mixed_sentiment_all</th>\n",
       "      <th>targets</th>\n",
       "      <th>text_length_all</th>\n",
       "      <th>prolific_score</th>\n",
       "      <th>prolific_indicator_all</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e1cf0eb65b6d3071f489de9</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.32</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9569</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>771.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Hello everyone. Thank you. Taking the time to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5e1cf0eb65b6d3071f489de9</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.32</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9569</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>771.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Again, as I talked about those great organizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e1cf0eb65b6d3071f489de9</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.32</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9569</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>771.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>So I'm pretty experienced at the moment. I'm c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55d06fd334e9060012e5781c</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>MED</td>\n",
       "      <td>424.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Hi, I am Kathy. I'd love to be considered for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55d06fd334e9060012e5781c</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>MED</td>\n",
       "      <td>424.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>It's been about five days, but I am reminding ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             participant_id  collective  contrast  goal  goals2  list  \\\n",
       "0  5e1cf0eb65b6d3071f489de9        0.35      1.07  0.43    0.32  6.96   \n",
       "1  5e1cf0eb65b6d3071f489de9        0.35      1.07  0.43    0.32  6.96   \n",
       "2  5e1cf0eb65b6d3071f489de9        0.35      1.07  0.43    0.32  6.96   \n",
       "3  55d06fd334e9060012e5781c        0.30      0.67  0.30    0.20  2.83   \n",
       "4  55d06fd334e9060012e5781c        0.30      0.67  0.30    0.20  2.83   \n",
       "\n",
       "   metaphor  moral  question  story  ...  positive_sentiment_all  \\\n",
       "0      0.94   2.36      0.01   0.46  ...                  0.9569   \n",
       "1      0.94   2.36      0.01   0.46  ...                  0.9569   \n",
       "2      0.94   2.36      0.01   0.46  ...                  0.9569   \n",
       "3      0.71   0.22      0.01   0.60  ...                  0.1587   \n",
       "4      0.71   0.22      0.01   0.60  ...                  0.1587   \n",
       "\n",
       "   negative_sentiment_all  neutra_sentiment_all  mixed_sentiment_all targets  \\\n",
       "0                  0.0007                0.0417               0.0007    HIGH   \n",
       "1                  0.0007                0.0417               0.0007    HIGH   \n",
       "2                  0.0007                0.0417               0.0007    HIGH   \n",
       "3                  0.0055                0.8350               0.0009     MED   \n",
       "4                  0.0055                0.8350               0.0009     MED   \n",
       "\n",
       "  text_length_all prolific_score  prolific_indicator_all  chunk_id  \\\n",
       "0           771.0          100.0                       2         0   \n",
       "1           771.0          100.0                       2         1   \n",
       "2           771.0          100.0                       2         2   \n",
       "3           424.0           99.0                       2         0   \n",
       "4           424.0           99.0                       2         1   \n",
       "\n",
       "                                          chunk_text  \n",
       "0  Hello everyone. Thank you. Taking the time to ...  \n",
       "1  Again, as I talked about those great organizat...  \n",
       "2  So I'm pretty experienced at the moment. I'm c...  \n",
       "3  Hi, I am Kathy. I'd love to be considered for ...  \n",
       "4  It's been about five days, but I am reminding ...  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_data_df = pd.read_csv(\"../../data/chunked_dataset.csv\")\n",
    "chunked_data_df = chunked_data_df.dropna()\n",
    "chunked_data_df = chunked_data_df.reset_index(drop=True)\n",
    "chunked_data_df = chunked_data_df.drop(columns=[\"Unnamed: 0\"])\n",
    "chunked_data_df_texts = chunked_data_df[\"chunk_text\"]\n",
    "print(chunked_data_df.shape)\n",
    "chunked_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9916, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>sEXT</th>\n",
       "      <th>sNEU</th>\n",
       "      <th>sAGR</th>\n",
       "      <th>sCON</th>\n",
       "      <th>sOPN</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "      <th>DATE</th>\n",
       "      <th>NETWORKSIZE</th>\n",
       "      <th>BETWEENNESS</th>\n",
       "      <th>NBETWEENNESS</th>\n",
       "      <th>DENSITY</th>\n",
       "      <th>BROKERAGE</th>\n",
       "      <th>NBROKERAGE</th>\n",
       "      <th>TRANSITIVITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes the sound of thunder.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>06/19/09 03:21 PM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is so sleepy it's not even funny that's she ca...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>07/02/09 08:41 AM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is sore and wants the knot of muscles at the b...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>06/15/09 01:15 PM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes how the day sounds in this new song.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>06/22/09 04:48 AM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is home. &lt;3</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>07/20/09 02:31 AM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            #AUTHID  \\\n",
       "0  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "1  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "2  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "3  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "4  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "\n",
       "                                              STATUS  sEXT  sNEU  sAGR  sCON  \\\n",
       "0                        likes the sound of thunder.  2.65   3.0  3.15  3.25   \n",
       "1  is so sleepy it's not even funny that's she ca...  2.65   3.0  3.15  3.25   \n",
       "2  is sore and wants the knot of muscles at the b...  2.65   3.0  3.15  3.25   \n",
       "3         likes how the day sounds in this new song.  2.65   3.0  3.15  3.25   \n",
       "4                                        is home. <3  2.65   3.0  3.15  3.25   \n",
       "\n",
       "   sOPN cEXT cNEU cAGR cCON cOPN               DATE  NETWORKSIZE  BETWEENNESS  \\\n",
       "0   4.4    n    y    n    n    y  06/19/09 03:21 PM        180.0      14861.6   \n",
       "1   4.4    n    y    n    n    y  07/02/09 08:41 AM        180.0      14861.6   \n",
       "2   4.4    n    y    n    n    y  06/15/09 01:15 PM        180.0      14861.6   \n",
       "3   4.4    n    y    n    n    y  06/22/09 04:48 AM        180.0      14861.6   \n",
       "4   4.4    n    y    n    n    y  07/20/09 02:31 AM        180.0      14861.6   \n",
       "\n",
       "   NBETWEENNESS  DENSITY  BROKERAGE  NBROKERAGE  TRANSITIVITY  \n",
       "0         93.29     0.03    15661.0        0.49           0.1  \n",
       "1         93.29     0.03    15661.0        0.49           0.1  \n",
       "2         93.29     0.03    15661.0        0.49           0.1  \n",
       "3         93.29     0.03    15661.0        0.49           0.1  \n",
       "4         93.29     0.03    15661.0        0.49           0.1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_personality_df = pd.read_csv(\"../../external_datasets/my_personality/my_personality.csv\", encoding=\"ISO-8859-1\")\n",
    "my_personality_df = my_personality_df.dropna()\n",
    "my_personality_df = my_personality_df.reset_index(drop=True)\n",
    "my_personality_df_texts = my_personality_df[\"STATUS\"]\n",
    "print(my_personality_df.shape)\n",
    "my_personality_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding the Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_batch(batch, tokenizer, max_length=512):\n",
    "    return tokenizer(\n",
    "        batch,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_embeddings(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_cls_embeddings = []\n",
    "    all_mean_embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "            all_cls_embeddings.append(cls_embeddings.cpu().numpy())\n",
    "\n",
    "            mean_embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "            all_mean_embeddings.append(mean_embeddings.cpu().numpy())\n",
    "\n",
    "    all_cls_embeddings = np.concatenate(all_cls_embeddings, axis=0)\n",
    "    all_mean_embeddings = np.concatenate(all_mean_embeddings, axis=0)\n",
    "\n",
    "    return all_cls_embeddings, all_mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "\n",
    "def pipe(texts, model, tokenizer, device, saving_path):\n",
    "    dataloader = DataLoader(\n",
    "        texts,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=lambda b: tokenize_batch(b, tokenizer),\n",
    "    )\n",
    "    cls_embeddings, mean_embeddings = generate_embeddings(\n",
    "        model,\n",
    "        dataloader,\n",
    "        device,\n",
    "    )\n",
    "    np.savez(\n",
    "        saving_path,\n",
    "        cls_embeddings=cls_embeddings,\n",
    "        mean_embeddings=mean_embeddings,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-roberta-large-v1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [11:59<00:00, 11.60s/it]\n"
     ]
    }
   ],
   "source": [
    "pipe(\n",
    "    data_df_texts,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    \"../../data/data_df_roberta_embeddings.npz\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [24:26<00:00,  9.40s/it]\n"
     ]
    }
   ],
   "source": [
    "pipe(\n",
    "    chunked_data_df_texts,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    \"../../data/chunked_data_df_roberta_embeddings.npz\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(\n",
    "    my_personality_df_texts,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    \"../../external_datasets/my_personality/my_personality_df_roberta_embeddings.npz\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Microsoft / DeBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/deberta-v3-base\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [09:22<00:00,  9.07s/it]\n"
     ]
    }
   ],
   "source": [
    "pipe(\n",
    "    data_df_texts,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    \"../../data/data_df_deberta_embeddings.npz\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [19:00<00:00,  7.31s/it]\n"
     ]
    }
   ],
   "source": [
    "pipe(\n",
    "    chunked_data_df_texts,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    \"../../data/chunked_data_df_deberta_embeddings.npz\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(\n",
    "    my_personality_df_texts,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    \"../../external_datasets/my_personality/my_personality_df_deberta_embeddings.npz\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
