{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding the Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we precompute the embeddings of the texts using different models. This will help us to quickly load the embeddings in the future and to avoid recomputing them in each iteration and in each model training. the embeddings are saved along with the data.\n",
    "\n",
    "Note that these embeddings are only usable when we are considering the model freezed. In the fine tuning procedures, precomputed embeddings are not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import CLIPTokenizer, CLIPModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_excel(\"../../data/dataset.xlsx\")\n",
    "data_df = data_df.dropna()\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "data_df = data_df.drop(columns=[\"Unnamed: 0\"])\n",
    "print(data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_personality_df = pd.read_csv(\"../../external_datasets/my_personality/my_personality.csv\", encoding=\"ISO-8859-1\")\n",
    "my_personality_df = my_personality_df.dropna()\n",
    "my_personality_df = my_personality_df.reset_index(drop=True)\n",
    "print(my_personality_df.shape)\n",
    "my_personality_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_df = pd.read_csv(\"../../external_datasets/social/social.csv\")\n",
    "social_df = social_df.dropna()\n",
    "social_df = social_df.reset_index(drop=True)\n",
    "print(social_df.shape)\n",
    "social_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_texts = data_df[\"final_text\"]\n",
    "my_personality_df_texts = my_personality_df[\"STATUS\"]\n",
    "social_df_texts = social_df[\"status_update\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding the Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_batch(batch, tokenizer, max_length=512):\n",
    "    return tokenizer(\n",
    "        batch,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_embeddings(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_cls_embeddings = []\n",
    "    all_mean_embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "            all_cls_embeddings.append(cls_embeddings.cpu().numpy())\n",
    "\n",
    "            mean_embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "            all_mean_embeddings.append(mean_embeddings.cpu().numpy())\n",
    "\n",
    "    all_cls_embeddings = np.concatenate(all_cls_embeddings, axis=0)\n",
    "    all_mean_embeddings = np.concatenate(all_mean_embeddings, axis=0)\n",
    "\n",
    "    return all_cls_embeddings, all_mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "\n",
    "def pipe(texts, model, tokenizer, device, saving_path):\n",
    "    dataloader = DataLoader(\n",
    "        texts,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=lambda b: tokenize_batch(b, tokenizer),\n",
    "    )\n",
    "    cls_embeddings, mean_embeddings = generate_embeddings(\n",
    "        model,\n",
    "        dataloader,\n",
    "        device,\n",
    "    )\n",
    "    np.savez(\n",
    "        saving_path,\n",
    "        cls_embeddings=cls_embeddings,\n",
    "        mean_embeddings=mean_embeddings,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-roberta-large-v1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "pipe(data_df_texts, model, tokenizer, device, \"../../data/data_df_embeddings.npz\")\n",
    "pipe(my_personality_df_texts, model, tokenizer, device, \"../../data/my_personality_df_embeddings.npz\")\n",
    "pipe(social_df_texts, model, tokenizer, device, \"../../data/social_df_embeddings.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
