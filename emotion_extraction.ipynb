{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"idiap\"\n",
    "dataset = \"idiap_chunked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"my_personality\":\n",
    "    target_vars_names = [\n",
    "        \"sEXT\",\n",
    "        \"sNEU\",\n",
    "        \"sAGR\",\n",
    "        \"sCON\",\n",
    "        \"sOPN\",\n",
    "    ]\n",
    "    train = pd.read_csv(\n",
    "        \"data/my_personality/my_personality.csv\",\n",
    "        encoding=\"ISO-8859-1\",\n",
    "    )\n",
    "    train.rename(columns={\"STATUS\": \"text\"}, inplace=True)\n",
    "elif dataset == \"idiap\":\n",
    "    target_vars_names = [\n",
    "        \"hones16\",\n",
    "        \"emoti16\",\n",
    "        \"extra16\",\n",
    "        \"agree16\",\n",
    "        \"consc16\",\n",
    "        \"openn16\",\n",
    "        \"icar_hat0\",\n",
    "        \"icar_hat1\",\n",
    "        \"icar_hat2\",\n",
    "    ]\n",
    "    train = pd.read_excel(\"data/idiap/dataset.xlsx\")\n",
    "    train.rename(columns={\"final_text\": \"text\"}, inplace=True)\n",
    "else:\n",
    "    target_vars_names = [\n",
    "        \"hones16\",\n",
    "        \"emoti16\",\n",
    "        \"extra16\",\n",
    "        \"agree16\",\n",
    "        \"consc16\",\n",
    "        \"openn16\",\n",
    "        \"icar_hat0\",\n",
    "        \"icar_hat1\",\n",
    "        \"icar_hat2\",\n",
    "    ]\n",
    "    train = pd.read_csv(\"data/idiap_chunked/chunked_dataset.csv\")\n",
    "    train.rename(columns={\"chunk_text\": \"text\"}, inplace=True)\n",
    "\n",
    "target_vars = train[target_vars_names]\n",
    "target_vars = (target_vars - target_vars.min()) / (target_vars.max() - target_vars.min())\n",
    "target_vars = target_vars.reset_index(drop=True).to_numpy()\n",
    "texts = train[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4988/4988 [09:28<00:00,  8.78it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bhadresh-savani/bert-base-go-emotion\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "emotion_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "def extract_features(texts):\n",
    "    features = []\n",
    "    for text in tqdm(texts):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = emotion_model(**inputs)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1)\n",
    "        features.append(probabilities[0].numpy())\n",
    "    return np.array(features)\n",
    "\n",
    "features = extract_features(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-19 15:03:08,137] A new study created in memory with name: no-name-dbeadf67-2138-46fa-a193-eb93d7aeac09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-19 15:03:08,630] Trial 0 finished with value: 0.3292394628611032 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.22148231622564474, 'learning_rate': 0.00034105814438628774}. Best is trial 0 with value: 0.3292394628611032.\n",
      "[I 2024-12-19 15:03:08,953] Trial 1 finished with value: 0.11119330174038783 and parameters: {'hidden_units': 128, 'num_layers': 1, 'dropout_rate': 0.4565413363163112, 'learning_rate': 0.0030291044042120747}. Best is trial 1 with value: 0.11119330174038783.\n",
      "[I 2024-12-19 15:03:09,521] Trial 2 finished with value: 0.13180305610845694 and parameters: {'hidden_units': 128, 'num_layers': 2, 'dropout_rate': 0.33555273931665847, 'learning_rate': 0.0004705238978690638}. Best is trial 1 with value: 0.11119330174038783.\n",
      "[I 2024-12-19 15:03:09,960] Trial 3 finished with value: 0.10724950553949876 and parameters: {'hidden_units': 128, 'num_layers': 2, 'dropout_rate': 0.08609155694936721, 'learning_rate': 0.0060035799568489865}. Best is trial 3 with value: 0.10724950553949876.\n",
      "[I 2024-12-19 15:03:10,653] Trial 4 finished with value: 0.20802187627044916 and parameters: {'hidden_units': 128, 'num_layers': 3, 'dropout_rate': 0.18573185019306038, 'learning_rate': 0.00029308355737412084}. Best is trial 3 with value: 0.10724950553949876.\n",
      "[I 2024-12-19 15:03:11,154] Trial 5 finished with value: 0.10998695715442355 and parameters: {'hidden_units': 96, 'num_layers': 3, 'dropout_rate': 0.2011588821887631, 'learning_rate': 0.00143357012533134}. Best is trial 3 with value: 0.10724950553949876.\n",
      "[I 2024-12-19 15:03:11,394] Trial 6 finished with value: 0.24667783094666676 and parameters: {'hidden_units': 128, 'num_layers': 1, 'dropout_rate': 0.45487932773305034, 'learning_rate': 0.0007168769668215443}. Best is trial 3 with value: 0.10724950553949876.\n",
      "[I 2024-12-19 15:03:12,300] Trial 7 finished with value: 0.10689999575422922 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.27912715503864577, 'learning_rate': 0.005694615848170065}. Best is trial 7 with value: 0.10689999575422922.\n",
      "[I 2024-12-19 15:03:12,555] Trial 8 finished with value: 0.16324435455489109 and parameters: {'hidden_units': 128, 'num_layers': 1, 'dropout_rate': 0.22558655458330662, 'learning_rate': 0.0008543507387190081}. Best is trial 7 with value: 0.10689999575422922.\n",
      "[I 2024-12-19 15:03:13,170] Trial 9 finished with value: 0.10830205478654847 and parameters: {'hidden_units': 160, 'num_layers': 2, 'dropout_rate': 0.42082634206651454, 'learning_rate': 0.00104090866262972}. Best is trial 7 with value: 0.10689999575422922.\n",
      "[I 2024-12-19 15:03:14,620] Trial 10 finished with value: 0.11159936131257558 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.03440297386305724, 'learning_rate': 0.009759408387537248}. Best is trial 7 with value: 0.10689999575422922.\n",
      "[I 2024-12-19 15:03:14,819] Trial 11 finished with value: 0.10760337474555533 and parameters: {'hidden_units': 32, 'num_layers': 2, 'dropout_rate': 0.05973071502574064, 'learning_rate': 0.009268820470147375}. Best is trial 7 with value: 0.10689999575422922.\n",
      "[I 2024-12-19 15:03:15,718] Trial 12 finished with value: 0.10880623864833613 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.12766941429492437, 'learning_rate': 0.003857345492025643}. Best is trial 7 with value: 0.10689999575422922.\n",
      "[I 2024-12-19 15:03:16,095] Trial 13 finished with value: 0.6110904983357831 and parameters: {'hidden_units': 64, 'num_layers': 2, 'dropout_rate': 0.32121477088163003, 'learning_rate': 0.0001173097846530743}. Best is trial 7 with value: 0.10689999575422922.\n",
      "[I 2024-12-19 15:03:16,951] Trial 14 finished with value: 0.11475047414612728 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.32005010987823834, 'learning_rate': 0.0038079294125090883}. Best is trial 7 with value: 0.10689999575422922.\n",
      "[I 2024-12-19 15:03:18,402] Trial 15 finished with value: 0.10695306511230847 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.12410334902025334, 'learning_rate': 0.002188977886770683}. Best is trial 7 with value: 0.10689999575422922.\n",
      "[I 2024-12-19 15:03:19,860] Trial 16 finished with value: 0.10662563685292917 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.14393267037315605, 'learning_rate': 0.0019546329501322107}. Best is trial 16 with value: 0.10662563685292917.\n",
      "[I 2024-12-19 15:03:21,260] Trial 17 finished with value: 0.11795336114751048 and parameters: {'hidden_units': 224, 'num_layers': 3, 'dropout_rate': 0.26254960603939803, 'learning_rate': 0.0016368344354251222}. Best is trial 16 with value: 0.10662563685292917.\n",
      "[I 2024-12-19 15:03:22,858] Trial 18 finished with value: 0.11070593172303743 and parameters: {'hidden_units': 224, 'num_layers': 3, 'dropout_rate': 0.151669135884479, 'learning_rate': 0.005727522807484454}. Best is trial 16 with value: 0.10662563685292917.\n",
      "[I 2024-12-19 15:03:24,616] Trial 19 finished with value: 0.10838792105694568 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.27822363348478224, 'learning_rate': 0.0023863610151494815}. Best is trial 16 with value: 0.10662563685292917.\n",
      "[I 2024-12-19 15:03:25,584] Trial 20 finished with value: 0.11262328904163794 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.3860226871898628, 'learning_rate': 0.006123987346518402}. Best is trial 16 with value: 0.10662563685292917.\n",
      "[I 2024-12-19 15:03:27,093] Trial 21 finished with value: 0.10725962472533847 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.12076611361483235, 'learning_rate': 0.0022562594997426687}. Best is trial 16 with value: 0.10662563685292917.\n",
      "[I 2024-12-19 15:03:28,833] Trial 22 finished with value: 0.11140958972262438 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.15852710617023252, 'learning_rate': 0.0017075088246231184}. Best is trial 16 with value: 0.10662563685292917.\n",
      "[I 2024-12-19 15:03:30,343] Trial 23 finished with value: 0.10829222110000836 and parameters: {'hidden_units': 224, 'num_layers': 3, 'dropout_rate': 0.0031372620209345198, 'learning_rate': 0.0040794029344054785}. Best is trial 16 with value: 0.10662563685292917.\n",
      "[I 2024-12-19 15:03:32,005] Trial 24 finished with value: 0.10970192146403039 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.09000212620065565, 'learning_rate': 0.0012385652502393087}. Best is trial 16 with value: 0.10662563685292917.\n",
      "[I 2024-12-19 15:03:33,104] Trial 25 finished with value: 0.10894382164492802 and parameters: {'hidden_units': 224, 'num_layers': 2, 'dropout_rate': 0.18389698074795371, 'learning_rate': 0.002433801600332647}. Best is trial 16 with value: 0.10662563685292917.\n",
      "[I 2024-12-19 15:03:34,643] Trial 26 finished with value: 0.10747880332512053 and parameters: {'hidden_units': 192, 'num_layers': 3, 'dropout_rate': 0.2722866584301337, 'learning_rate': 0.0006764118700165838}. Best is trial 16 with value: 0.10662563685292917.\n",
      "[I 2024-12-19 15:03:35,460] Trial 27 finished with value: 0.10697828173016573 and parameters: {'hidden_units': 160, 'num_layers': 2, 'dropout_rate': 0.09752792417711789, 'learning_rate': 0.0051840137392193}. Best is trial 16 with value: 0.10662563685292917.\n",
      "[I 2024-12-19 15:03:37,141] Trial 28 finished with value: 0.10662208253217469 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.37148402796454333, 'learning_rate': 0.0020695929489492}. Best is trial 28 with value: 0.10662208253217469.\n",
      "[I 2024-12-19 15:03:37,734] Trial 29 finished with value: 0.40479505727980963 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.3772683597290358, 'learning_rate': 0.00028362662378301904}. Best is trial 28 with value: 0.10662208253217469.\n",
      "[I 2024-12-19 15:03:38,794] Trial 30 finished with value: 0.11325323730705811 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.4999969361621911, 'learning_rate': 0.007696463117006758}. Best is trial 28 with value: 0.10662208253217469.\n",
      "[I 2024-12-19 15:03:40,479] Trial 31 finished with value: 0.10736986007319242 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.23245226032219377, 'learning_rate': 0.0018416851576276538}. Best is trial 28 with value: 0.10662208253217469.\n",
      "[I 2024-12-19 15:03:41,971] Trial 32 finished with value: 0.10881308402901307 and parameters: {'hidden_units': 224, 'num_layers': 3, 'dropout_rate': 0.2964514767598668, 'learning_rate': 0.003287881329261667}. Best is trial 28 with value: 0.10662208253217469.\n",
      "[I 2024-12-19 15:03:43,828] Trial 33 finished with value: 0.11100302274324444 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.3777226519047781, 'learning_rate': 0.0031228121834615073}. Best is trial 28 with value: 0.10662208253217469.\n",
      "[I 2024-12-19 15:03:45,230] Trial 34 finished with value: 0.10900670351536086 and parameters: {'hidden_units': 224, 'num_layers': 3, 'dropout_rate': 0.357091543254148, 'learning_rate': 0.00048780458331066474}. Best is trial 28 with value: 0.10662208253217469.\n",
      "[I 2024-12-19 15:03:46,282] Trial 35 finished with value: 0.10724066971545623 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.4184606188218001, 'learning_rate': 0.002180727802073273}. Best is trial 28 with value: 0.10662208253217469.\n",
      "[I 2024-12-19 15:03:47,846] Trial 36 finished with value: 0.11013014990177425 and parameters: {'hidden_units': 224, 'num_layers': 3, 'dropout_rate': 0.20824306938313722, 'learning_rate': 0.0011930621168474386}. Best is trial 28 with value: 0.10662208253217469.\n",
      "[I 2024-12-19 15:03:49,203] Trial 37 finished with value: 0.11434416385276228 and parameters: {'hidden_units': 192, 'num_layers': 3, 'dropout_rate': 0.16452146320847222, 'learning_rate': 0.004754548114459193}. Best is trial 28 with value: 0.10662208253217469.\n",
      "[I 2024-12-19 15:03:49,501] Trial 38 finished with value: 0.11621840386208812 and parameters: {'hidden_units': 96, 'num_layers': 1, 'dropout_rate': 0.24271091662924363, 'learning_rate': 0.002615964519352912}. Best is trial 28 with value: 0.10662208253217469.\n",
      "[I 2024-12-19 15:03:50,902] Trial 39 finished with value: 0.11379852946838288 and parameters: {'hidden_units': 160, 'num_layers': 3, 'dropout_rate': 0.058843788092178884, 'learning_rate': 0.0014910632240571747}. Best is trial 28 with value: 0.10662208253217469.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.37148402796454333, 'learning_rate': 0.0020695929489492}\n",
      "Epoch [10/100], Loss: 0.0359\n",
      "Epoch [20/100], Loss: 0.0440\n",
      "Epoch [30/100], Loss: 0.0372\n",
      "Epoch [40/100], Loss: 0.0324\n",
      "Epoch [50/100], Loss: 0.0307\n",
      "Epoch [60/100], Loss: 0.0305\n",
      "Epoch [70/100], Loss: 0.0295\n",
      "Epoch [80/100], Loss: 0.0289\n",
      "Epoch [90/100], Loss: 0.0282\n",
      "Epoch [100/100], Loss: 0.0277\n",
      "MAE per output: [0.13595506 0.14191837 0.14253739 0.14024242 0.14809994 0.14151378\n",
      " 0.03880633 0.04252824 0.04869937]\n",
      "RMSE per output: [0.16884131 0.17574281 0.17549298 0.17193784 0.18770432 0.17405805\n",
      " 0.05816682 0.0622656  0.06883622]\n",
      "Mean MAE: 0.10892232330549799\n",
      "Mean RMSE: 0.1381162154507429\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target_vars, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "\n",
    "class EmotionRegressor(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_units, num_layers, dropout_rate):\n",
    "        super(EmotionRegressor, self).__init__()\n",
    "        layers = []\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(\n",
    "                nn.Linear(\n",
    "                    input_size if len(layers) == 0 else hidden_units, hidden_units\n",
    "                )\n",
    "            )\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "        layers.append(nn.Linear(hidden_units, output_size))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    hidden_units = trial.suggest_int(\"hidden_units\", 32, 256, step=32)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 0.5)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "\n",
    "    model = EmotionRegressor(\n",
    "        input_size=X_train.shape[1],\n",
    "        output_size=y_train.shape[1],\n",
    "        hidden_units=hidden_units,\n",
    "        num_layers=num_layers,\n",
    "        dropout_rate=dropout_rate,\n",
    "    )\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    epochs = 50\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test_tensor).numpy()\n",
    "\n",
    "    rmse_per_output = np.sqrt(\n",
    "        mean_squared_error(y_test, predictions, multioutput=\"raw_values\")\n",
    "    )\n",
    "    mean_rmse = np.mean(rmse_per_output)\n",
    "\n",
    "    mae_per_output = mean_absolute_error(y_test, predictions, multioutput=\"raw_values\")\n",
    "    mean_mae = np.mean(mae_per_output)\n",
    "\n",
    "    return mean_mae\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=40)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "best_params = study.best_params\n",
    "final_model = EmotionRegressor(\n",
    "    input_size=X_train.shape[1],\n",
    "    output_size=y_train.shape[1],\n",
    "    hidden_units=best_params[\"hidden_units\"],\n",
    "    num_layers=best_params[\"num_layers\"],\n",
    "    dropout_rate=best_params[\"dropout_rate\"],\n",
    ")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=best_params[\"learning_rate\"])\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    final_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = final_model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = final_model(X_test_tensor).numpy()\n",
    "\n",
    "mae_per_output = mean_absolute_error(y_test, predictions, multioutput=\"raw_values\")\n",
    "rmse_per_output = np.sqrt(\n",
    "    mean_squared_error(y_test, predictions, multioutput=\"raw_values\")\n",
    ")\n",
    "mean_mae = np.mean(mae_per_output)\n",
    "mean_rmse = np.mean(rmse_per_output)\n",
    "\n",
    "print(\"MAE per output:\", mae_per_output)\n",
    "print(\"RMSE per output:\", rmse_per_output)\n",
    "print(\"Mean MAE:\", mean_mae)\n",
    "print(\"Mean RMSE:\", mean_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
