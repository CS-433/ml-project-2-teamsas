{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel(\"data/idiap/dataset.xlsx\")\n",
    "train = train.dropna()\n",
    "train = train.reset_index(drop=True)\n",
    "train = train.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "texts = train[\"final_text\"]\n",
    "target_vars_names = [\n",
    "    \"hones16\",\n",
    "    \"emoti16\",\n",
    "    \"extra16\",\n",
    "    \"agree16\",\n",
    "    \"consc16\",\n",
    "    \"openn16\",\n",
    "    \"icar_hat0\",\n",
    "    \"icar_hat1\",\n",
    "    \"icar_hat2\",\n",
    "]\n",
    "target_vars = train[target_vars_names]\n",
    "target_vars = (target_vars - target_vars.min()) / (target_vars.max() - target_vars.min())\n",
    "target_vars = target_vars.reset_index(drop=True).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1983/1983 [05:32<00:00,  5.97it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "model_name = \"bhadresh-savani/bert-base-go-emotion\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "emotion_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def extract_features(texts):\n",
    "    features = []\n",
    "    for text in tqdm(texts):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = emotion_model(**inputs)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1)\n",
    "        features.append(probabilities[0].numpy())\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "features = extract_features(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 11:49:10,170] A new study created in memory with name: no-name-7abd0534-04e3-4d57-b728-d51fed91fd95\n",
      "[I 2024-12-18 11:49:10,361] Trial 0 finished with value: -0.04306295900271347 and parameters: {'hidden_units': 128, 'num_layers': 2, 'dropout_rate': 0.13258246046155997, 'learning_rate': 0.0035382542651959145}. Best is trial 0 with value: -0.04306295900271347.\n",
      "[I 2024-12-18 11:49:10,641] Trial 1 finished with value: -28.76821069090125 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.11570093443505686, 'learning_rate': 0.00014463578991026716}. Best is trial 0 with value: -0.04306295900271347.\n",
      "[I 2024-12-18 11:49:10,826] Trial 2 finished with value: -0.04122410494492858 and parameters: {'hidden_units': 128, 'num_layers': 2, 'dropout_rate': 0.30313461542155923, 'learning_rate': 0.0017279242577491762}. Best is trial 2 with value: -0.04122410494492858.\n",
      "[I 2024-12-18 11:49:11,013] Trial 3 finished with value: -0.07641612864529845 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.30282320449556493, 'learning_rate': 0.0027664594998430803}. Best is trial 2 with value: -0.04122410494492858.\n",
      "[I 2024-12-18 11:49:11,300] Trial 4 finished with value: -0.04555891448071213 and parameters: {'hidden_units': 96, 'num_layers': 3, 'dropout_rate': 0.3711808738437179, 'learning_rate': 0.006088381111096067}. Best is trial 2 with value: -0.04122410494492858.\n",
      "[I 2024-12-18 11:49:11,492] Trial 5 finished with value: -0.010525376078348149 and parameters: {'hidden_units': 160, 'num_layers': 1, 'dropout_rate': 0.3616589559105991, 'learning_rate': 0.009495033071055781}. Best is trial 5 with value: -0.010525376078348149.\n",
      "[I 2024-12-18 11:49:11,584] Trial 6 finished with value: -0.33360425953659817 and parameters: {'hidden_units': 32, 'num_layers': 2, 'dropout_rate': 0.391821868727152, 'learning_rate': 0.006475010087615049}. Best is trial 5 with value: -0.010525376078348149.\n",
      "[I 2024-12-18 11:49:11,674] Trial 7 finished with value: -59.563129387859185 and parameters: {'hidden_units': 32, 'num_layers': 2, 'dropout_rate': 0.207637417265011, 'learning_rate': 0.0001570703783132095}. Best is trial 5 with value: -0.010525376078348149.\n",
      "[I 2024-12-18 11:49:12,190] Trial 8 finished with value: -0.44109256266794833 and parameters: {'hidden_units': 224, 'num_layers': 3, 'dropout_rate': 0.4400674968426782, 'learning_rate': 0.0028456981075905535}. Best is trial 5 with value: -0.010525376078348149.\n",
      "[I 2024-12-18 11:49:12,306] Trial 9 finished with value: -43.47529490382083 and parameters: {'hidden_units': 128, 'num_layers': 1, 'dropout_rate': 0.3032292554783834, 'learning_rate': 0.00025157501477304447}. Best is trial 5 with value: -0.010525376078348149.\n",
      "[I 2024-12-18 11:49:12,443] Trial 10 finished with value: -6.464112093852733 and parameters: {'hidden_units': 192, 'num_layers': 1, 'dropout_rate': 0.031185800196498248, 'learning_rate': 0.0006144572060232914}. Best is trial 5 with value: -0.010525376078348149.\n",
      "[I 2024-12-18 11:49:12,582] Trial 11 finished with value: -8.747024599162637 and parameters: {'hidden_units': 96, 'num_layers': 1, 'dropout_rate': 0.4653547227489739, 'learning_rate': 0.0008373311163817936}. Best is trial 5 with value: -0.010525376078348149.\n",
      "[I 2024-12-18 11:49:12,915] Trial 12 finished with value: -0.34086132780903994 and parameters: {'hidden_units': 160, 'num_layers': 3, 'dropout_rate': 0.24314233636847588, 'learning_rate': 0.009463140121983965}. Best is trial 5 with value: -0.010525376078348149.\n",
      "[I 2024-12-18 11:49:13,129] Trial 13 finished with value: -0.1177999461152089 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.3244312088636403, 'learning_rate': 0.001360121489609912}. Best is trial 5 with value: -0.010525376078348149.\n",
      "[I 2024-12-18 11:49:13,359] Trial 14 finished with value: -14.830749821596378 and parameters: {'hidden_units': 96, 'num_layers': 2, 'dropout_rate': 0.49749725080105506, 'learning_rate': 0.0004278893818917427}. Best is trial 5 with value: -0.010525376078348149.\n",
      "[I 2024-12-18 11:49:13,482] Trial 15 finished with value: -0.22234022694843614 and parameters: {'hidden_units': 160, 'num_layers': 1, 'dropout_rate': 0.1952481638007239, 'learning_rate': 0.0013117335647422287}. Best is trial 5 with value: -0.010525376078348149.\n",
      "[I 2024-12-18 11:49:13,685] Trial 16 finished with value: -0.14939141613776286 and parameters: {'hidden_units': 64, 'num_layers': 3, 'dropout_rate': 0.38180106782824264, 'learning_rate': 0.0018358507919647978}. Best is trial 5 with value: -0.010525376078348149.\n",
      "[I 2024-12-18 11:49:13,971] Trial 17 finished with value: -0.25349948061200767 and parameters: {'hidden_units': 160, 'num_layers': 2, 'dropout_rate': 0.33337935719398454, 'learning_rate': 0.004677230473299225}. Best is trial 5 with value: -0.010525376078348149.\n",
      "[I 2024-12-18 11:49:14,117] Trial 18 finished with value: -0.009771964953166469 and parameters: {'hidden_units': 192, 'num_layers': 1, 'dropout_rate': 0.2526675922199817, 'learning_rate': 0.008542917087050083}. Best is trial 18 with value: -0.009771964953166469.\n",
      "[I 2024-12-18 11:49:14,251] Trial 19 finished with value: -0.1328357516992603 and parameters: {'hidden_units': 192, 'num_layers': 1, 'dropout_rate': 0.24568716444931865, 'learning_rate': 0.009810473129390403}. Best is trial 18 with value: -0.009771964953166469.\n",
      "[I 2024-12-18 11:49:14,476] Trial 20 finished with value: -0.02600704798960211 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.17859771580083775, 'learning_rate': 0.005680228711157725}. Best is trial 18 with value: -0.009771964953166469.\n",
      "[I 2024-12-18 11:49:14,730] Trial 21 finished with value: -0.009753068973420617 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.15059637214789562, 'learning_rate': 0.0061999050851647185}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:14,907] Trial 22 finished with value: -0.1545341989043402 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.0812343559406193, 'learning_rate': 0.009538250228072734}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:15,130] Trial 23 finished with value: -0.0980098236125569 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.1541071799653064, 'learning_rate': 0.0038506491543872116}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:15,281] Trial 24 finished with value: -0.052958009915916406 and parameters: {'hidden_units': 192, 'num_layers': 1, 'dropout_rate': 0.07518400799441155, 'learning_rate': 0.006840841723941775}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:15,539] Trial 25 finished with value: -0.10371386803038608 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.2614253664367091, 'learning_rate': 0.0026020342531619584}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:15,678] Trial 26 finished with value: -0.04224732788673052 and parameters: {'hidden_units': 160, 'num_layers': 1, 'dropout_rate': 0.23018564774924344, 'learning_rate': 0.004646019635470278}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:15,819] Trial 27 finished with value: -0.09476404761991214 and parameters: {'hidden_units': 192, 'num_layers': 1, 'dropout_rate': 0.0024790443818742958, 'learning_rate': 0.0073939274916191965}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:16,011] Trial 28 finished with value: -0.22294828999831331 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.41960012776925115, 'learning_rate': 0.004376922204836946}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:16,209] Trial 29 finished with value: -0.19880582189456797 and parameters: {'hidden_units': 128, 'num_layers': 2, 'dropout_rate': 0.11077605928583459, 'learning_rate': 0.002337365649525282}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:16,399] Trial 30 finished with value: -0.05540092892591285 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.14188755232708267, 'learning_rate': 0.0032708790020467174}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:16,633] Trial 31 finished with value: -0.04368256822838221 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.18147040335278844, 'learning_rate': 0.0056407091414873226}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:16,827] Trial 32 finished with value: -0.12502975568561447 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.15881749704056836, 'learning_rate': 0.007844941752347692}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:16,978] Trial 33 finished with value: -0.0530293545195034 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.27649366690497446, 'learning_rate': 0.005104405911398252}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:17,397] Trial 34 finished with value: -0.01643422308102116 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.1083932370424621, 'learning_rate': 0.0035523081864002565}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:17,693] Trial 35 finished with value: -0.0998343802673768 and parameters: {'hidden_units': 224, 'num_layers': 2, 'dropout_rate': 0.1059222678985613, 'learning_rate': 0.003452733888615719}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:17,954] Trial 36 finished with value: -0.07881603809671928 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.0438326489226111, 'learning_rate': 0.007671867941378357}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:18,206] Trial 37 finished with value: -0.27616040353279175 and parameters: {'hidden_units': 160, 'num_layers': 2, 'dropout_rate': 0.3453507812338525, 'learning_rate': 0.0020153145619552643}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:18,601] Trial 38 finished with value: -0.22737000301931795 and parameters: {'hidden_units': 192, 'num_layers': 3, 'dropout_rate': 0.2142022740979664, 'learning_rate': 0.003958926251463423}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:18,791] Trial 39 finished with value: -0.10110714710690766 and parameters: {'hidden_units': 128, 'num_layers': 2, 'dropout_rate': 0.07848905705745783, 'learning_rate': 0.006187967551738278}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:19,085] Trial 40 finished with value: -32.960870078993075 and parameters: {'hidden_units': 224, 'num_layers': 2, 'dropout_rate': 0.2870238798620317, 'learning_rate': 0.00011527693872331723}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:19,268] Trial 41 finished with value: -0.011072335698757861 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.17442368616037546, 'learning_rate': 0.005702223105379063}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:19,459] Trial 42 finished with value: -0.034881593490812074 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.12756276789698745, 'learning_rate': 0.008320958605565651}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:19,649] Trial 43 finished with value: -0.05495733296220722 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.17202501231989897, 'learning_rate': 0.005976877948829567}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:19,810] Trial 44 finished with value: -0.05852037853247517 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.20619139845595347, 'learning_rate': 0.003257699306722327}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:20,011] Trial 45 finished with value: -0.023061632308345657 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.09927377091077039, 'learning_rate': 0.00718259990079534}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:20,182] Trial 46 finished with value: -0.03429769526030527 and parameters: {'hidden_units': 64, 'num_layers': 3, 'dropout_rate': 0.40555069367279184, 'learning_rate': 0.00879302431777753}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:20,320] Trial 47 finished with value: -35.94842660670824 and parameters: {'hidden_units': 160, 'num_layers': 1, 'dropout_rate': 0.13939352973707772, 'learning_rate': 0.00026394941532556173}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:20,481] Trial 48 finished with value: -0.1576770980576102 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.04759623227388915, 'learning_rate': 0.005118342253094034}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:20,752] Trial 49 finished with value: -0.0542446106003727 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.36216049796847477, 'learning_rate': 0.0011047125391456137}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:20,852] Trial 50 finished with value: -19.947413911231934 and parameters: {'hidden_units': 96, 'num_layers': 1, 'dropout_rate': 0.3128403952561467, 'learning_rate': 0.0006987644996775303}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:21,045] Trial 51 finished with value: -0.09585447255841734 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.10797899945725274, 'learning_rate': 0.006636543087114928}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:21,277] Trial 52 finished with value: -0.02246392861090143 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.2222884641323467, 'learning_rate': 0.007243404336974083}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:21,469] Trial 53 finished with value: -0.07761339632712255 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.19656691381483665, 'learning_rate': 0.009614224879065913}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:21,631] Trial 54 finished with value: -0.1232561848899451 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.2371984677833281, 'learning_rate': 0.004014762828639493}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:21,841] Trial 55 finished with value: -0.03355338258670785 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.26063445427618254, 'learning_rate': 0.005367653781781618}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:22,046] Trial 56 finished with value: -0.11359003435943836 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.22712077282720802, 'learning_rate': 0.00989987006148045}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:22,202] Trial 57 finished with value: -0.047768528127748594 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.47285565412064956, 'learning_rate': 0.006689719873177497}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:22,331] Trial 58 finished with value: -0.0773019610094951 and parameters: {'hidden_units': 160, 'num_layers': 1, 'dropout_rate': 0.15765244689660415, 'learning_rate': 0.0027084514137832617}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:22,739] Trial 59 finished with value: -0.09113787360072115 and parameters: {'hidden_units': 192, 'num_layers': 3, 'dropout_rate': 0.2825305714899116, 'learning_rate': 0.004909150757163889}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:23,153] Trial 60 finished with value: -0.02346108419871752 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.12725514329435547, 'learning_rate': 0.008057924783053592}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:23,339] Trial 61 finished with value: -0.1075864292893788 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.0925266778994232, 'learning_rate': 0.007678661692813483}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:23,533] Trial 62 finished with value: -0.05433448312588234 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.1861310886105793, 'learning_rate': 0.006728329447737057}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:23,723] Trial 63 finished with value: -0.06344814974603878 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.06813534081643388, 'learning_rate': 0.005745090042524491}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:23,873] Trial 64 finished with value: -0.17243781322512278 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.17051246553243163, 'learning_rate': 0.004363700275390979}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:24,062] Trial 65 finished with value: -0.014221266439748538 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.21555345170793822, 'learning_rate': 0.007078380709011306}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:24,217] Trial 66 finished with value: -0.19528362736816615 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.21503847190299974, 'learning_rate': 0.008965266203362037}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:24,320] Trial 67 finished with value: -0.138421878261903 and parameters: {'hidden_units': 128, 'num_layers': 1, 'dropout_rate': 0.2575451573242593, 'learning_rate': 0.0015756870410676429}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:24,511] Trial 68 finished with value: -0.05672234681027 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.19162874924631274, 'learning_rate': 0.0060599925404918546}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:24,696] Trial 69 finished with value: -0.056588670026729515 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.15207128222171387, 'learning_rate': 0.0030237886323627324}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:24,835] Trial 70 finished with value: -21.041936695804207 and parameters: {'hidden_units': 192, 'num_layers': 1, 'dropout_rate': 0.22782226568622993, 'learning_rate': 0.00043335043441418864}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:25,032] Trial 71 finished with value: -0.05632868163770123 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.09392040393687842, 'learning_rate': 0.007629652300900609}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:25,216] Trial 72 finished with value: -0.05619183702165795 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.16884553669297772, 'learning_rate': 0.007204613625935026}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:25,370] Trial 73 finished with value: -0.038615123269412494 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.12040471636660532, 'learning_rate': 0.008426202356296403}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:25,555] Trial 74 finished with value: -0.1231187260061388 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.14264804423857874, 'learning_rate': 0.004358209463377319}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:25,703] Trial 75 finished with value: -0.07436652898366988 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.2980379662180197, 'learning_rate': 0.006734693718693833}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:25,891] Trial 76 finished with value: -0.049981546156553 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.05702062984434222, 'learning_rate': 0.0036808324493626684}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:26,080] Trial 77 finished with value: -0.03064252812816648 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.20595061740281742, 'learning_rate': 0.005404249815316497}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:26,380] Trial 78 finished with value: -0.21642385357125823 and parameters: {'hidden_units': 224, 'num_layers': 2, 'dropout_rate': 0.4442751701813086, 'learning_rate': 0.008917092094536864}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:26,471] Trial 79 finished with value: -0.07321468615261899 and parameters: {'hidden_units': 96, 'num_layers': 1, 'dropout_rate': 0.09689401746305346, 'learning_rate': 0.004584527768992671}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:26,803] Trial 80 finished with value: -0.207879818399998 and parameters: {'hidden_units': 160, 'num_layers': 3, 'dropout_rate': 0.2721358208038683, 'learning_rate': 0.005919362076182456}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:27,208] Trial 81 finished with value: -0.05214440386289724 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.12766380557002782, 'learning_rate': 0.008095018105450501}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:27,613] Trial 82 finished with value: -0.17373834866203544 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.1173980660254262, 'learning_rate': 0.009877841138066423}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:28,015] Trial 83 finished with value: -0.03447017187330638 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.13494753059698092, 'learning_rate': 0.007362949004415239}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:28,411] Trial 84 finished with value: -0.11942518724719979 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.24901269812091073, 'learning_rate': 0.008372876155425165}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:28,707] Trial 85 finished with value: -0.17798661577023245 and parameters: {'hidden_units': 224, 'num_layers': 2, 'dropout_rate': 0.14875168315916076, 'learning_rate': 0.006298228271569826}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:28,900] Trial 86 finished with value: -0.10955837916944396 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.16582234580969357, 'learning_rate': 0.005171668055461978}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:29,313] Trial 87 finished with value: -0.02595260581699514 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.18046093561212642, 'learning_rate': 0.007102066281536205}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:29,460] Trial 88 finished with value: -0.17468050784591932 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.029090640684454272, 'learning_rate': 0.00871024976831926}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:29,860] Trial 89 finished with value: -0.35697005333635634 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.34766922776872905, 'learning_rate': 0.009980992673583529}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:29,958] Trial 90 finished with value: -0.249852720274206 and parameters: {'hidden_units': 128, 'num_layers': 1, 'dropout_rate': 0.19787320361838476, 'learning_rate': 0.0063901129147765235}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:30,362] Trial 91 finished with value: -0.029452407047380575 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.1834780460175556, 'learning_rate': 0.007237277930632948}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:30,817] Trial 92 finished with value: -0.0296056889525483 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.22028056460148332, 'learning_rate': 0.008022482668741112}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:31,227] Trial 93 finished with value: -0.021854755746215624 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.10391589124873668, 'learning_rate': 0.005624792261541131}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:31,678] Trial 94 finished with value: -0.018779778821366055 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.10080072960774082, 'learning_rate': 0.0023594352644892565}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:32,084] Trial 95 finished with value: -0.02802189801898204 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.08111176406331073, 'learning_rate': 0.0020276315295748885}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:32,235] Trial 96 finished with value: -0.12426926615928963 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.09238455435245656, 'learning_rate': 0.004009513657697385}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:32,354] Trial 97 finished with value: -0.16989445015975047 and parameters: {'hidden_units': 160, 'num_layers': 1, 'dropout_rate': 0.10769130771788143, 'learning_rate': 0.004747355321500578}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:32,758] Trial 98 finished with value: -0.13839601189850181 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.38256492711118817, 'learning_rate': 0.002420217748333938}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:32,812] Trial 99 finished with value: -0.07542465756837564 and parameters: {'hidden_units': 32, 'num_layers': 1, 'dropout_rate': 0.07004409712506217, 'learning_rate': 0.0034516182838957095}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:33,003] Trial 100 finished with value: -0.05331425400568793 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.23636237118367098, 'learning_rate': 0.0029319305704619335}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:33,411] Trial 101 finished with value: -0.05860155951252277 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.0990455445342201, 'learning_rate': 0.005397175698718815}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:33,822] Trial 102 finished with value: -0.03556542736127431 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.12318425295410616, 'learning_rate': 0.005771408028298224}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:34,227] Trial 103 finished with value: -0.02722574519965093 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.16186711900758843, 'learning_rate': 0.006419703746981638}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:34,628] Trial 104 finished with value: -0.0136361889223504 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.13431845941472237, 'learning_rate': 0.0089261790169807}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:34,743] Trial 105 finished with value: -0.19649752822394784 and parameters: {'hidden_units': 64, 'num_layers': 2, 'dropout_rate': 0.13679153118581042, 'learning_rate': 0.009205540024251781}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:35,039] Trial 106 finished with value: -0.054021783838333004 and parameters: {'hidden_units': 224, 'num_layers': 2, 'dropout_rate': 0.06266766191918777, 'learning_rate': 0.004299099508383732}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:35,250] Trial 107 finished with value: -0.05392690533511408 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.14754141482198457, 'learning_rate': 0.006994051430707861}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:35,438] Trial 108 finished with value: -0.04694760874819305 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.08168375577482906, 'learning_rate': 0.007678577483810425}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:35,602] Trial 109 finished with value: -0.13256730596149693 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.11432675202095767, 'learning_rate': 0.004938445005478483}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:35,862] Trial 110 finished with value: -0.15559349760400035 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.08687838966900278, 'learning_rate': 0.0011782434018756836}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:36,265] Trial 111 finished with value: -0.0890802329836386 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.10516788461795862, 'learning_rate': 0.008805179846038295}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:36,671] Trial 112 finished with value: -0.09587627051046363 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.13169426567276327, 'learning_rate': 0.008039048817471639}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:37,124] Trial 113 finished with value: -0.04159247634961913 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.12761962997278342, 'learning_rate': 0.0063208588939820684}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:37,729] Trial 114 finished with value: -0.23314969905770846 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.11576033156826177, 'learning_rate': 0.005659387969129669}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:38,158] Trial 115 finished with value: -0.033872751262138484 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.15778853130025336, 'learning_rate': 0.0070081787641674866}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:38,599] Trial 116 finished with value: -0.10087708630818093 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.20355161584364032, 'learning_rate': 0.00937561696077342}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:39,009] Trial 117 finished with value: -0.07380254687057647 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.05221692315040318, 'learning_rate': 0.007941307048219893}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:39,192] Trial 118 finished with value: -0.049080196349260495 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.1728025838150368, 'learning_rate': 0.006012906826177635}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:39,353] Trial 119 finished with value: -0.059708255498192586 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.10547108871060173, 'learning_rate': 0.008610586262395697}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:39,772] Trial 120 finished with value: -0.08550266716131465 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.14216205531524237, 'learning_rate': 0.0015988093063912154}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:40,184] Trial 121 finished with value: -0.011153750594199886 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.18676727601687013, 'learning_rate': 0.007083905983447786}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:40,591] Trial 122 finished with value: -0.030309498962634143 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.3201991441723534, 'learning_rate': 0.006884546770872561}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:40,998] Trial 123 finished with value: -0.03275728757183346 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.2196699302789012, 'learning_rate': 0.007721208853880271}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:41,409] Trial 124 finished with value: -10.08224248512823 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.17494024810748796, 'learning_rate': 0.0001811454312671272}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:41,817] Trial 125 finished with value: -0.21096257797800855 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.40863115093972824, 'learning_rate': 0.005018897884553359}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:42,015] Trial 126 finished with value: -0.2081205711734259 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.18731319419237252, 'learning_rate': 0.009226281114529}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:42,314] Trial 127 finished with value: -0.1773675223581025 and parameters: {'hidden_units': 224, 'num_layers': 2, 'dropout_rate': 0.2091498879744893, 'learning_rate': 0.005578458597802653}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:42,448] Trial 128 finished with value: -0.10425275250976625 and parameters: {'hidden_units': 192, 'num_layers': 1, 'dropout_rate': 0.23952957713107195, 'learning_rate': 0.0007985217883975547}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:42,569] Trial 129 finished with value: -0.02203714594318244 and parameters: {'hidden_units': 160, 'num_layers': 1, 'dropout_rate': 0.15331074321705665, 'learning_rate': 0.006438208177261324}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:42,691] Trial 130 finished with value: -0.08031986760736709 and parameters: {'hidden_units': 160, 'num_layers': 1, 'dropout_rate': 0.19437615290976792, 'learning_rate': 0.0038113611695808035}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:42,810] Trial 131 finished with value: -0.08750218758607647 and parameters: {'hidden_units': 160, 'num_layers': 1, 'dropout_rate': 0.1520287406910021, 'learning_rate': 0.007378067299287439}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:42,929] Trial 132 finished with value: -0.023029059920022403 and parameters: {'hidden_units': 160, 'num_layers': 1, 'dropout_rate': 0.13457778237994888, 'learning_rate': 0.0063537404228438555}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:43,052] Trial 133 finished with value: -0.0400929201905703 and parameters: {'hidden_units': 160, 'num_layers': 1, 'dropout_rate': 0.15904675310657862, 'learning_rate': 0.006473989605478177}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:43,174] Trial 134 finished with value: -0.10886844165890065 and parameters: {'hidden_units': 160, 'num_layers': 1, 'dropout_rate': 0.14069540889725762, 'learning_rate': 0.00613870540211701}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:43,274] Trial 135 finished with value: -0.08715042880755523 and parameters: {'hidden_units': 128, 'num_layers': 1, 'dropout_rate': 0.11718919845629051, 'learning_rate': 0.005163261751444322}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:43,395] Trial 136 finished with value: -0.0699924215748309 and parameters: {'hidden_units': 160, 'num_layers': 1, 'dropout_rate': 0.10107712244536625, 'learning_rate': 0.004718709627616846}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:43,518] Trial 137 finished with value: -0.024285793241211114 and parameters: {'hidden_units': 160, 'num_layers': 1, 'dropout_rate': 0.13334531492685392, 'learning_rate': 0.007206276925178464}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:43,657] Trial 138 finished with value: -0.11149129672244773 and parameters: {'hidden_units': 192, 'num_layers': 1, 'dropout_rate': 0.17610737823898615, 'learning_rate': 0.004286915417640737}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:43,783] Trial 139 finished with value: -0.024463589412107196 and parameters: {'hidden_units': 160, 'num_layers': 1, 'dropout_rate': 0.16470626764665505, 'learning_rate': 0.009964467871159967}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:43,890] Trial 140 finished with value: -0.04499137873202049 and parameters: {'hidden_units': 128, 'num_layers': 1, 'dropout_rate': 0.03342149314818718, 'learning_rate': 0.008374039137881673}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:44,084] Trial 141 finished with value: -0.053736001084859625 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.12001201796449482, 'learning_rate': 0.006508777410808616}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:44,489] Trial 142 finished with value: -0.380540081780041 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.12855957015725974, 'learning_rate': 0.0005163458175653509}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:44,678] Trial 143 finished with value: -0.07364540018694314 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.07330048303784568, 'learning_rate': 0.00824266519753277}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:44,867] Trial 144 finished with value: -0.028267588075676912 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.08990796812405007, 'learning_rate': 0.005764326328056411}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:45,278] Trial 145 finished with value: -0.0895296686355868 and parameters: {'hidden_units': 256, 'num_layers': 2, 'dropout_rate': 0.1490472539097374, 'learning_rate': 0.007553559059896387}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:45,466] Trial 146 finished with value: -0.043033142202509124 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.22382377308805176, 'learning_rate': 0.006778024181631645}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:45,692] Trial 147 finished with value: -0.13062532907518234 and parameters: {'hidden_units': 160, 'num_layers': 2, 'dropout_rate': 0.479329636171074, 'learning_rate': 0.008936374016921178}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:46,268] Trial 148 finished with value: -0.014296533643853353 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.10799380781298899, 'learning_rate': 0.005475934785085555}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:46,864] Trial 149 finished with value: -0.16800396774179852 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.10783829449515357, 'learning_rate': 0.00544713944923619}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:47,450] Trial 150 finished with value: -0.06831777423030716 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.4360313945494381, 'learning_rate': 0.006053259192050079}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:48,037] Trial 151 finished with value: -0.011726123232878805 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.12451136013492116, 'learning_rate': 0.007176044503581887}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:48,622] Trial 152 finished with value: -0.022006859728521382 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.0958299882485612, 'learning_rate': 0.007196701734116129}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:49,218] Trial 153 finished with value: -0.028506903056244245 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.11362987401593584, 'learning_rate': 0.006676435990610818}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:49,810] Trial 154 finished with value: -0.04265841383193263 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.13864662505755995, 'learning_rate': 0.002019465619749257}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:50,425] Trial 155 finished with value: -0.14053908279809008 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.08758300820192691, 'learning_rate': 0.0032902493556841907}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:51,055] Trial 156 finished with value: -0.10585051601759433 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.12499872336974757, 'learning_rate': 0.005273326494718115}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:51,348] Trial 157 finished with value: -0.09496790566320151 and parameters: {'hidden_units': 96, 'num_layers': 3, 'dropout_rate': 0.1968942632164358, 'learning_rate': 0.007464913019473505}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:52,058] Trial 158 finished with value: -0.07844851952904344 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.25363457942537804, 'learning_rate': 0.005934201911485425}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:52,728] Trial 159 finished with value: -0.15885999195520484 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.35982547840421136, 'learning_rate': 0.004520667088807533}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:53,306] Trial 160 finished with value: -0.43264404707200815 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.09642071269563893, 'learning_rate': 0.008575341764912897}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:53,889] Trial 161 finished with value: -0.025803455255807614 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.07918953852072565, 'learning_rate': 0.006742163223457091}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:54,471] Trial 162 finished with value: -0.032512266309571235 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.1044116820497498, 'learning_rate': 0.00732965994656561}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:54,663] Trial 163 finished with value: -0.07088646216041027 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.1194448274373706, 'learning_rate': 0.006177071855645433}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:55,276] Trial 164 finished with value: -0.14504843963514152 and parameters: {'hidden_units': 256, 'num_layers': 3, 'dropout_rate': 0.2682537695522383, 'learning_rate': 0.008017309925014414}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:55,460] Trial 165 finished with value: -0.011245685461246454 and parameters: {'hidden_units': 192, 'num_layers': 1, 'dropout_rate': 0.1480999230773682, 'learning_rate': 0.006983276162126652}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:55,628] Trial 166 finished with value: -0.05871190934282512 and parameters: {'hidden_units': 192, 'num_layers': 1, 'dropout_rate': 0.1572709937297491, 'learning_rate': 0.005642188001397288}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:55,763] Trial 167 finished with value: -0.019136068650393065 and parameters: {'hidden_units': 160, 'num_layers': 1, 'dropout_rate': 0.14562698975740088, 'learning_rate': 0.009327292352025169}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:55,892] Trial 168 finished with value: -0.1437522878204692 and parameters: {'hidden_units': 192, 'num_layers': 1, 'dropout_rate': 0.14469940886184635, 'learning_rate': 0.009975330333721015}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:55,995] Trial 169 finished with value: -0.019785441188644955 and parameters: {'hidden_units': 128, 'num_layers': 1, 'dropout_rate': 0.18587868304814953, 'learning_rate': 0.008671074790912359}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:56,139] Trial 170 finished with value: -0.049488680523028364 and parameters: {'hidden_units': 128, 'num_layers': 1, 'dropout_rate': 0.18359580611344595, 'learning_rate': 0.009097096526869557}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:56,292] Trial 171 finished with value: -0.031798372588160574 and parameters: {'hidden_units': 160, 'num_layers': 1, 'dropout_rate': 0.16316296114950746, 'learning_rate': 0.008060832649612694}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:56,438] Trial 172 finished with value: -0.041727672845575964 and parameters: {'hidden_units': 128, 'num_layers': 1, 'dropout_rate': 0.16859733476157862, 'learning_rate': 0.008932189492407368}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:56,561] Trial 173 finished with value: -0.03967344591485909 and parameters: {'hidden_units': 128, 'num_layers': 1, 'dropout_rate': 0.20886994959819807, 'learning_rate': 0.0074217515197170115}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:56,687] Trial 174 finished with value: -0.03171172291165441 and parameters: {'hidden_units': 160, 'num_layers': 1, 'dropout_rate': 0.15254652778833472, 'learning_rate': 0.00847250708866072}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:56,794] Trial 175 finished with value: -0.05212207355686327 and parameters: {'hidden_units': 128, 'num_layers': 1, 'dropout_rate': 0.18037179034929968, 'learning_rate': 0.007036562313370908}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:56,946] Trial 176 finished with value: -0.12169767068969278 and parameters: {'hidden_units': 224, 'num_layers': 1, 'dropout_rate': 0.20129678022127187, 'learning_rate': 0.009546902100101309}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:57,296] Trial 177 finished with value: -0.23564246267893837 and parameters: {'hidden_units': 160, 'num_layers': 2, 'dropout_rate': 0.18976926726161736, 'learning_rate': 0.007828854921973652}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:57,540] Trial 178 finished with value: -0.030286012927243977 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.23008460895168303, 'learning_rate': 0.00241281835252564}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:57,789] Trial 179 finished with value: -0.08445794694329328 and parameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.14495805026622607, 'learning_rate': 0.006643053516389693}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:58,146] Trial 180 finished with value: -0.01577196102471512 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.13304940259122613, 'learning_rate': 0.00855835014317959}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:58,434] Trial 181 finished with value: -0.011654792256087787 and parameters: {'hidden_units': 160, 'num_layers': 2, 'dropout_rate': 0.13161209584501685, 'learning_rate': 0.009000904163715078}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:58,663] Trial 182 finished with value: -0.014323299941328811 and parameters: {'hidden_units': 160, 'num_layers': 2, 'dropout_rate': 0.130976102890823, 'learning_rate': 0.009243179711027134}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:58,967] Trial 183 finished with value: -0.027471173845406243 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.12940698746688759, 'learning_rate': 0.009252069523077033}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:59,230] Trial 184 finished with value: -0.014304796501955128 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.1133664816308414, 'learning_rate': 0.00984307629704322}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:59,495] Trial 185 finished with value: -0.07912083768930472 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.11570919278713307, 'learning_rate': 0.00969310916454204}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:49:59,759] Trial 186 finished with value: -0.021655049809925966 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.135655882365804, 'learning_rate': 0.008535897803339378}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:50:00,055] Trial 187 finished with value: -0.08338903964625802 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.12820188578192074, 'learning_rate': 0.009951150451199481}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:50:00,357] Trial 188 finished with value: -0.02458859924245334 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.14366321928580297, 'learning_rate': 0.008315259972286016}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:50:00,658] Trial 189 finished with value: -0.025117211426976132 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.1371812369285263, 'learning_rate': 0.008913286847216331}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:50:00,941] Trial 190 finished with value: -0.08252352201963714 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.12193896421403694, 'learning_rate': 0.008523489788793042}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:50:01,234] Trial 191 finished with value: -0.06730541363718608 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.10842436753137263, 'learning_rate': 0.009151907473669679}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:50:01,514] Trial 192 finished with value: -0.07228173138547417 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.2963973174413257, 'learning_rate': 0.008038510476644119}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:50:01,789] Trial 193 finished with value: -0.02979929998880663 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.1355546118028378, 'learning_rate': 0.009978784300896973}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:50:02,019] Trial 194 finished with value: -0.02892107705821339 and parameters: {'hidden_units': 160, 'num_layers': 2, 'dropout_rate': 0.11220232292148331, 'learning_rate': 0.008694927033630855}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:50:02,294] Trial 195 finished with value: -0.027952994408882215 and parameters: {'hidden_units': 192, 'num_layers': 2, 'dropout_rate': 0.1231162028454399, 'learning_rate': 0.007782543646135592}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:50:02,526] Trial 196 finished with value: -0.012506891780312477 and parameters: {'hidden_units': 160, 'num_layers': 2, 'dropout_rate': 0.15193039835682362, 'learning_rate': 0.009045218128323857}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:50:02,785] Trial 197 finished with value: -0.2144774976424643 and parameters: {'hidden_units': 160, 'num_layers': 2, 'dropout_rate': 0.16410901673671313, 'learning_rate': 0.008869741562762455}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:50:03,054] Trial 198 finished with value: -0.18458969070364692 and parameters: {'hidden_units': 160, 'num_layers': 2, 'dropout_rate': 0.1512621661729247, 'learning_rate': 0.007942622742303571}. Best is trial 21 with value: -0.009753068973420617.\n",
      "[I 2024-12-18 11:50:03,330] Trial 199 finished with value: -0.014487384209316797 and parameters: {'hidden_units': 160, 'num_layers': 2, 'dropout_rate': 0.17405938084391104, 'learning_rate': 0.009060898963964741}. Best is trial 21 with value: -0.009753068973420617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'hidden_units': 256, 'num_layers': 1, 'dropout_rate': 0.15059637214789562, 'learning_rate': 0.0061999050851647185}\n",
      "Epoch [10/100], Loss: 0.0780\n",
      "Epoch [20/100], Loss: 0.0396\n",
      "Epoch [30/100], Loss: 0.0284\n",
      "Epoch [40/100], Loss: 0.0251\n",
      "Epoch [50/100], Loss: 0.0242\n",
      "Epoch [60/100], Loss: 0.0237\n",
      "Epoch [70/100], Loss: 0.0237\n",
      "Epoch [80/100], Loss: 0.0233\n",
      "Epoch [90/100], Loss: 0.0234\n",
      "Epoch [100/100], Loss: 0.0232\n",
      "MAE per output: [0.13412758 0.1385297  0.13788654 0.14045485 0.14759735 0.13571472\n",
      " 0.03290575 0.03928731 0.04646209]\n",
      "RMSE per output: [0.1672936  0.17404351 0.16892969 0.17406826 0.18916002 0.16915717\n",
      " 0.05337999 0.0566868  0.0648716 ]\n",
      "R2 per output: [-0.00375136  0.00385267 -0.00546433 -0.00600259 -0.00184933 -0.00382385\n",
      " -0.0096159  -0.00829628 -0.01181128]\n",
      "Mean MAE: 0.1058850981680787\n",
      "Mean RMSE: 0.13528784862395893\n",
      "Mean R2: -0.005195806682625623\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target_vars, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "\n",
    "class EmotionRegressor(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_units, num_layers, dropout_rate):\n",
    "        super(EmotionRegressor, self).__init__()\n",
    "        layers = []\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(\n",
    "                nn.Linear(\n",
    "                    input_size if len(layers) == 0 else hidden_units, hidden_units\n",
    "                )\n",
    "            )\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "        layers.append(nn.Linear(hidden_units, output_size))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    hidden_units = trial.suggest_int(\"hidden_units\", 32, 256, step=32)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 0.5)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = EmotionRegressor(\n",
    "        input_size=X_train.shape[1],\n",
    "        output_size=y_train.shape[1],\n",
    "        hidden_units=hidden_units,\n",
    "        num_layers=num_layers,\n",
    "        dropout_rate=dropout_rate,\n",
    "    )\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    epochs = 50\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test_tensor).numpy()\n",
    "\n",
    "    # Calculate mean RMSE for the objective function\n",
    "    rmse_per_output = np.sqrt(\n",
    "        mean_squared_error(y_test, predictions, multioutput=\"raw_values\")\n",
    "    )\n",
    "    mean_rmse = np.mean(rmse_per_output)\n",
    "\n",
    "    r2_per_output = r2_score(y_test, predictions, multioutput=\"raw_values\")\n",
    "    mean_r2 = np.mean(r2_per_output)\n",
    "    return mean_r2\n",
    "\n",
    "\n",
    "# Optimize the hyperparameters with Optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "# Train and evaluate the final model with the best hyperparameters\n",
    "best_params = study.best_params\n",
    "final_model = EmotionRegressor(\n",
    "    input_size=X_train.shape[1],\n",
    "    output_size=y_train.shape[1],\n",
    "    hidden_units=best_params[\"hidden_units\"],\n",
    "    num_layers=best_params[\"num_layers\"],\n",
    "    dropout_rate=best_params[\"dropout_rate\"],\n",
    ")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=best_params[\"learning_rate\"])\n",
    "\n",
    "# Train the final model\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    final_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = final_model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluate the final model\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = final_model(X_test_tensor).numpy()\n",
    "\n",
    "mae_per_output = mean_absolute_error(y_test, predictions, multioutput=\"raw_values\")\n",
    "rmse_per_output = np.sqrt(\n",
    "    mean_squared_error(y_test, predictions, multioutput=\"raw_values\")\n",
    ")\n",
    "r2_per_output = r2_score(y_test, predictions, multioutput=\"raw_values\")\n",
    "mean_mae = np.mean(mae_per_output)\n",
    "mean_rmse = np.mean(rmse_per_output)\n",
    "mean_r2 = np.mean(r2_per_output)\n",
    "\n",
    "# Print results\n",
    "print(\"MAE per output:\", mae_per_output)\n",
    "print(\"RMSE per output:\", rmse_per_output)\n",
    "print(\"R2 per output:\", r2_per_output)\n",
    "print(\"Mean MAE:\", mean_mae)\n",
    "print(\"Mean RMSE:\", mean_rmse)\n",
    "print(\"Mean R2:\", mean_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 1586, Labels: 1586\n",
      "Validation samples: 397, Labels: 397\n",
      "First training sample: {'input_ids': tensor([  101,  7592,  1012,  8529,  1045,  2228,  2026,  2783,  2597,  2004,\n",
      "         2529,  4219,  2306,  2529,  4219,  1012,  1045,  2228,  1045,  2052,\n",
      "         2022,  2200,  4591,  2000,  2022,  3755,  2000,  1996,  3208,  1997,\n",
      "         1996, 17850,  2533,  1012,  1998,  1045,  2228,  2023,  2005,  2536,\n",
      "         4436,  1012,  1045,  2903,  2008,  2026,  4105,  2911,  2026,  4105,\n",
      "         4813,  2024,  2031,  5301, 24821,  2083,  2551,  2007,  2111,  2306,\n",
      "         2023,  3105,  1012,  1045,  1005,  2310,  4342,  1037,  2843,  2055,\n",
      "         1996, 16165,  1010,  2054,  1996,  5372,  8778,  2003,  2306,  1996,\n",
      "        16165,  1998,  2129,  2000,  6133,  2008,  6464,  2061,  2008,  5126,\n",
      "         2031,  1037,  2307,  3325,  2012,  2147,  2090,  2026,  3003,  5896,\n",
      "        11137,  2026,  4105,  4813,  1012,  1998,  2036,  1045,  2903,  2008,\n",
      "         2026,  3754,  2000,  6133,  2026,  3754,  2000,  2147,  2007,  2111,\n",
      "         2738,  2084,  2551,  2005,  1010,  1045,  2064,   102]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor([0.6559, 0.5385, 0.6739, 0.6087, 0.2297, 0.9043, 0.6961, 0.6795, 0.6669])}\n",
      "Batch 0: input_ids shape torch.Size([32, 128]), labels shape torch.Size([32, 9])\n",
      "Epoch [1/5]\n",
      "  Train Loss: 0.0572\n",
      "  Val Loss: 0.0231\n",
      "  Val MAE: 0.1134\n",
      "  Val RMSE: 0.1523\n",
      "  Val R2: -0.2220\n",
      "Epoch [2/5]\n",
      "  Train Loss: 0.0266\n",
      "  Val Loss: 0.0220\n",
      "  Val MAE: 0.1087\n",
      "  Val RMSE: 0.1488\n",
      "  Val R2: -0.0916\n",
      "Epoch [3/5]\n",
      "  Train Loss: 0.0245\n",
      "  Val Loss: 0.0226\n",
      "  Val MAE: 0.1097\n",
      "  Val RMSE: 0.1506\n",
      "  Val R2: -0.1141\n",
      "Epoch [4/5]\n",
      "  Train Loss: 0.0238\n",
      "  Val Loss: 0.0214\n",
      "  Val MAE: 0.1077\n",
      "  Val RMSE: 0.1468\n",
      "  Val R2: -0.0661\n",
      "Epoch [5/5]\n",
      "  Train Loss: 0.0231\n",
      "  Val Loss: 0.0213\n",
      "  Val MAE: 0.1065\n",
      "  Val RMSE: 0.1463\n",
      "  Val R2: -0.0265\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "train = pd.read_excel(\"data/idiap/dataset.xlsx\")\n",
    "train = train.dropna()\n",
    "train = train.reset_index(drop=True)\n",
    "train = train.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "texts = train[\"final_text\"]\n",
    "target_vars_names = [\n",
    "    \"hones16\",\n",
    "    \"emoti16\",\n",
    "    \"extra16\",\n",
    "    \"agree16\",\n",
    "    \"consc16\",\n",
    "    \"openn16\",\n",
    "    \"icar_hat0\",\n",
    "    \"icar_hat1\",\n",
    "    \"icar_hat2\",\n",
    "]\n",
    "target_vars = train[target_vars_names]\n",
    "target_vars = (target_vars - target_vars.min()) / (target_vars.max() - target_vars.min())\n",
    "target_vars = target_vars.reset_index(drop=True).to_numpy()\n",
    "\n",
    "# Train-test split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, target_vars, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Debug train-test split\n",
    "print(f\"Train samples: {len(train_texts)}, Labels: {len(train_labels)}\")\n",
    "print(f\"Validation samples: {len(val_texts)}, Labels: {len(val_labels)}\")\n",
    "\n",
    "# Load pretrained model and tokenizer\n",
    "model_name = \"bert-base-uncased\"  # Replace with your emotion model if available\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Configure LoRA\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.FEATURE_EXTRACTION,  # Feature extraction for regression\n",
    "    inference_mode=False,\n",
    "    r=8,  # Low-rank dimension\n",
    "    lora_alpha=16,  # Scaling factor\n",
    "    lora_dropout=0.1  # Dropout\n",
    ")\n",
    "lora_model = get_peft_model(base_model, lora_config)\n",
    "\n",
    "# Define the regression model\n",
    "class EmotionRegressor(nn.Module):\n",
    "    def __init__(self, base_model, output_size):\n",
    "        super(EmotionRegressor, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.regression_head = nn.Linear(base_model.config.hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]  # CLS token representation\n",
    "        regression_output = self.regression_head(cls_output)\n",
    "        return regression_output\n",
    "\n",
    "# Initialize the model\n",
    "output_size = target_vars.shape[1]\n",
    "full_model = EmotionRegressor(base_model=lora_model, output_size=output_size)\n",
    "\n",
    "# Dataset class\n",
    "class EmotionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            str(self.texts.iloc[idx]),  # Ensure text is a string\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = EmotionDataset(pd.Series(train_texts), train_labels, tokenizer)\n",
    "val_dataset = EmotionDataset(pd.Series(val_texts), val_labels, tokenizer)\n",
    "\n",
    "# Debug dataset\n",
    "print(\"First training sample:\", train_dataset[0])\n",
    "\n",
    "# Data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False, drop_last=False)\n",
    "\n",
    "# Debug DataLoader\n",
    "for i, batch in enumerate(train_loader):\n",
    "    print(f\"Batch {i}: input_ids shape {batch['input_ids'].shape}, labels shape {batch['labels'].shape}\")\n",
    "    break\n",
    "\n",
    "# Training setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "full_model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(full_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    full_model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = full_model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation phase\n",
    "    full_model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_predictions = []\n",
    "    val_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = full_model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            val_predictions.append(outputs.cpu().numpy())\n",
    "            val_targets.append(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    val_predictions = np.concatenate(val_predictions, axis=0)\n",
    "    val_targets = np.concatenate(val_targets, axis=0)\n",
    "    mae = mean_absolute_error(val_targets, val_predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(val_targets, val_predictions))\n",
    "    r2 = r2_score(val_targets, val_predictions)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"  Train Loss: {train_loss / len(train_loader):.4f}\")\n",
    "    print(f\"  Val Loss: {val_loss / len(val_loader):.4f}\")\n",
    "    print(f\"  Val MAE: {mae:.4f}\")\n",
    "    print(f\"  Val RMSE: {rmse:.4f}\")\n",
    "    print(f\"  Val R2: {r2:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(full_model.state_dict(), \"emotion_regressor.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
