{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Generation\n",
    "\n",
    "In this notebook, we aim to employ embedding methods of text and train a regression model on them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import LongformerTokenizer, LongformerModel\n",
    "from transformers import BigBirdTokenizer, BigBirdModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: to prevent unexpected behaviors.\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>collective</th>\n",
       "      <th>contrast</th>\n",
       "      <th>goal</th>\n",
       "      <th>goals2</th>\n",
       "      <th>list</th>\n",
       "      <th>metaphor</th>\n",
       "      <th>moral</th>\n",
       "      <th>question</th>\n",
       "      <th>story</th>\n",
       "      <th>...</th>\n",
       "      <th>final_text</th>\n",
       "      <th>overall_sentiment_all</th>\n",
       "      <th>positive_sentiment_all</th>\n",
       "      <th>negative_sentiment_all</th>\n",
       "      <th>neutra_sentiment_all</th>\n",
       "      <th>mixed_sentiment_all</th>\n",
       "      <th>targets</th>\n",
       "      <th>text_length_all</th>\n",
       "      <th>prolific_score</th>\n",
       "      <th>prolific_indicator_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e1cf0eb65b6d3071f489de9</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.32</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>Hello everyone. Thank you. Taking the time to ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.956900</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>771.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55d06fd334e9060012e5781c</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>Hi, I am Kathy. I'd love to be considered for ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0.158700</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>MED</td>\n",
       "      <td>424.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>615586b009f801c3f2d4af8d</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.26</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>uh yeah I I think I would be the best candidat...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.805100</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.174700</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>MED</td>\n",
       "      <td>449.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5847e60f73170700013697c6</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.12</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.09</td>\n",
       "      <td>...</td>\n",
       "      <td>Hello. Um I've of course a fair amount of expe...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.576100</td>\n",
       "      <td>0.118500</td>\n",
       "      <td>0.248400</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>611.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6086a11397234e7f83e4e793</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.76</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.22</td>\n",
       "      <td>7.92</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>Okay, so I would like to thank you for giving ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.851500</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.145600</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>611.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>5e43021e5bb25719df134c7c</td>\n",
       "      <td>0.63</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.45</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>I believe I'm the best person to take up this ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.683128</td>\n",
       "      <td>0.036325</td>\n",
       "      <td>0.183616</td>\n",
       "      <td>0.096930</td>\n",
       "      <td>MED</td>\n",
       "      <td>769.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>54b60d74fdf99b1ce0367ab5</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.42</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.20</td>\n",
       "      <td>...</td>\n",
       "      <td>Hi there. I definitely think I should be consi...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.699336</td>\n",
       "      <td>0.006666</td>\n",
       "      <td>0.228330</td>\n",
       "      <td>0.065668</td>\n",
       "      <td>MED</td>\n",
       "      <td>781.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>60fe95530ccb79107f63773e</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.89</td>\n",
       "      <td>...</td>\n",
       "      <td>as an undergraduate student, I studied at the ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.799731</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.199813</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>LOW</td>\n",
       "      <td>545.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>607deec383975f3377a28b9e</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>5.69</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.06</td>\n",
       "      <td>...</td>\n",
       "      <td>I've always been a confident person um I will ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.316924</td>\n",
       "      <td>0.257287</td>\n",
       "      <td>0.184135</td>\n",
       "      <td>0.241654</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>517.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>5eddb464a77718acaaa72ab5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.23</td>\n",
       "      <td>4.23</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.11</td>\n",
       "      <td>...</td>\n",
       "      <td>Okay, so you want a list of some of my leaders...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.633909</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>0.329303</td>\n",
       "      <td>0.030766</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>580.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1998 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                participant_id  collective  contrast  goal  goals2  list  \\\n",
       "0     5e1cf0eb65b6d3071f489de9        0.35      1.07  0.43    0.32  6.96   \n",
       "1     55d06fd334e9060012e5781c        0.30      0.67  0.30    0.20  2.83   \n",
       "2     615586b009f801c3f2d4af8d        0.18      0.74  0.16    0.26  3.40   \n",
       "3     5847e60f73170700013697c6        0.14      2.14  0.27    0.12  3.05   \n",
       "4     6086a11397234e7f83e4e793        0.90      4.76  0.86    0.22  7.92   \n",
       "...                        ...         ...       ...   ...     ...   ...   \n",
       "1993  5e43021e5bb25719df134c7c        0.63      3.18  0.73    0.45  6.20   \n",
       "1994  54b60d74fdf99b1ce0367ab5        0.51      1.72  1.35    0.30  5.42   \n",
       "1995  60fe95530ccb79107f63773e        0.11      0.12  0.14    0.11  6.20   \n",
       "1996  607deec383975f3377a28b9e        0.28      0.40  0.22    0.45  5.69   \n",
       "1997  5eddb464a77718acaaa72ab5        0.90      0.52  0.69    0.23  4.23   \n",
       "\n",
       "      metaphor  moral  question  story  ...  \\\n",
       "0         0.94   2.36      0.01   0.46  ...   \n",
       "1         0.71   0.22      0.01   0.60  ...   \n",
       "2         1.10   1.09      0.01   0.37  ...   \n",
       "3         0.49   0.46      0.00   1.09  ...   \n",
       "4         0.56   2.95      0.01   0.19  ...   \n",
       "...        ...    ...       ...    ...  ...   \n",
       "1993      0.65   4.03      0.01   0.26  ...   \n",
       "1994      0.55   2.54      0.01   1.20  ...   \n",
       "1995      0.19   0.98      0.01   0.89  ...   \n",
       "1996      0.38   0.59      0.01   1.06  ...   \n",
       "1997      1.08   2.67      0.86   0.11  ...   \n",
       "\n",
       "                                             final_text  \\\n",
       "0     Hello everyone. Thank you. Taking the time to ...   \n",
       "1     Hi, I am Kathy. I'd love to be considered for ...   \n",
       "2     uh yeah I I think I would be the best candidat...   \n",
       "3     Hello. Um I've of course a fair amount of expe...   \n",
       "4     Okay, so I would like to thank you for giving ...   \n",
       "...                                                 ...   \n",
       "1993  I believe I'm the best person to take up this ...   \n",
       "1994  Hi there. I definitely think I should be consi...   \n",
       "1995  as an undergraduate student, I studied at the ...   \n",
       "1996  I've always been a confident person um I will ...   \n",
       "1997  Okay, so you want a list of some of my leaders...   \n",
       "\n",
       "      overall_sentiment_all  positive_sentiment_all  negative_sentiment_all  \\\n",
       "0                  POSITIVE                0.956900                0.000700   \n",
       "1                   NEUTRAL                0.158700                0.005500   \n",
       "2                  POSITIVE                0.805100                0.016400   \n",
       "3                  POSITIVE                0.576100                0.118500   \n",
       "4                  POSITIVE                0.851500                0.001600   \n",
       "...                     ...                     ...                     ...   \n",
       "1993               POSITIVE                0.683128                0.036325   \n",
       "1994               POSITIVE                0.699336                0.006666   \n",
       "1995               POSITIVE                0.799731                0.000397   \n",
       "1996               POSITIVE                0.316924                0.257287   \n",
       "1997               POSITIVE                0.633909                0.006022   \n",
       "\n",
       "     neutra_sentiment_all mixed_sentiment_all targets  text_length_all  \\\n",
       "0                0.041700            0.000700    HIGH            771.0   \n",
       "1                0.835000            0.000900     MED            424.0   \n",
       "2                0.174700            0.003900     MED            449.0   \n",
       "3                0.248400            0.057000    HIGH            611.0   \n",
       "4                0.145600            0.001300    HIGH            611.0   \n",
       "...                   ...                 ...     ...              ...   \n",
       "1993             0.183616            0.096930     MED            769.0   \n",
       "1994             0.228330            0.065668     MED            781.0   \n",
       "1995             0.199813            0.000059     LOW            545.0   \n",
       "1996             0.184135            0.241654    HIGH            517.0   \n",
       "1997             0.329303            0.030766    HIGH            580.0   \n",
       "\n",
       "      prolific_score  prolific_indicator_all  \n",
       "0              100.0                       2  \n",
       "1               99.0                       2  \n",
       "2              100.0                       2  \n",
       "3              100.0                       2  \n",
       "4              100.0                       2  \n",
       "...              ...                     ...  \n",
       "1993           100.0                       2  \n",
       "1994            96.0                       1  \n",
       "1995           100.0                       2  \n",
       "1996           100.0                       2  \n",
       "1997            99.0                       2  \n",
       "\n",
       "[1998 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_excel(\"../data/dataset.xlsx\", index_col=0)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigBird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [1:41:38<00:00, 12.20s/it]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 4\n",
    "MAX_LENGTH = 2**12\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"device: {DEVICE}\")\n",
    "\n",
    "tokenizer = BigBirdTokenizer.from_pretrained(\"google/bigbird-roberta-base\")\n",
    "model = BigBirdModel.from_pretrained(\"google/bigbird-roberta-base\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "texts = data_df[\"final_text\"].tolist()\n",
    "num_batches = math.ceil(len(texts) / BATCH_SIZE)\n",
    "\n",
    "cls_embeddings = []\n",
    "avg_embeddings = []\n",
    "\n",
    "for i in tqdm(range(num_batches)):\n",
    "    batch_texts = texts[i * BATCH_SIZE : (i + 1) * BATCH_SIZE]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        batch_texts,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        add_special_tokens=True,\n",
    "    )\n",
    "    inputs = {key: value.to(DEVICE) for key, value in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "        batch_cls_embeddings = last_hidden_state[:, 0, :]\n",
    "\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "        batch_avg_embeddings = (last_hidden_state * attention_mask.unsqueeze(-1)).sum(dim=1) / attention_mask.sum(dim=1).unsqueeze(-1)\n",
    "\n",
    "    cls_embeddings.append(batch_cls_embeddings)\n",
    "    avg_embeddings.append(batch_avg_embeddings)\n",
    "\n",
    "cls_embeddings = torch.cat(cls_embeddings, dim=0)\n",
    "avg_embeddings = torch.cat(avg_embeddings, dim=0)\n",
    "\n",
    "with open(\"../embeddings/bigbird_cls_embeddings.pt\", \"wb\") as f:\n",
    "    torch.save(cls_embeddings, f)\n",
    "\n",
    "with open(\"../embeddings/bigbird_avg_embeddings.pt\", \"wb\") as f:\n",
    "    torch.save(avg_embeddings, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
